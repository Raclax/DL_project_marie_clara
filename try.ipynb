{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db017b04",
   "metadata": {},
   "source": [
    "# Project detection math expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ddb947",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483e785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x74a3c8c27a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, utils\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models.detection as detection\n",
    "# Install pix2text robustly using the current Python executable\n",
    "import sys, subprocess\n",
    "try:\n",
    "    import pix2text\n",
    "except Exception:\n",
    "    print('pix2text not found — installing via python -m pip')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pix2text>=1.1'])\n",
    "    import pix2text\n",
    "print('pix2text is available')\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce25700",
   "metadata": {},
   "source": [
    "## Pre treatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55a82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CROHMEDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset pour les expressions complètes (PNG + LG).\n",
    "    Chaque sample retourne :\n",
    "        - image : Tensor CxHxW\n",
    "        - target : dict contenant \"boxes\" et \"labels\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform=None, meta_classes=True):\n",
    "        \"\"\"\n",
    "        root : chemin du dossier contenant les PNG + LG\n",
    "        transform : transform PyTorch (augmentations, ToTensor, Resize…)\n",
    "        meta_classes : si True, map chaque label vers une méta-classe\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.meta_classes = meta_classes\n",
    "\n",
    "        # liste des fichiers PNG / LG\n",
    "        self.images = [f for f in os.listdir(root) if f.endswith(\".png\")]\n",
    "        self.images.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.root, img_name)\n",
    "\n",
    "        lg_name = img_name.replace(\".png\", \".lg\")\n",
    "        lg_path = os.path.join(self.root, lg_name)\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        with open(lg_path, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "            for line in f:\n",
    "                parts = [p.strip() for p in line.strip().split(\",\") if p.strip() != \"\"]\n",
    "                if len(parts) < 6:\n",
    "                    # fallback to whitespace splitting if commas are not reliable\n",
    "                    parts = [p.strip() for p in line.strip().split() if p.strip() != \"\"]\n",
    "\n",
    "                if len(parts) < 6:\n",
    "                    continue\n",
    "\n",
    "                label = parts[1]\n",
    "                try:\n",
    "                    xmin_s, ymin_s, xmax_s, ymax_s = parts[-4:]\n",
    "                    xmin = float(xmin_s)\n",
    "                    ymin = float(ymin_s)\n",
    "                    xmax = float(xmax_s)\n",
    "                    ymax = float(ymax_s)\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "                if xmax <= xmin or ymax <= ymin:\n",
    "                    warnings.warn(\n",
    "                            f\"Found invalid bbox in '{lg_path}': [xmin={xmin}, ymin={ymin}, xmax={xmax}, ymax={ymax}]. These boxes will be skipped.\")\n",
    "                    continue\n",
    "\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                labels.append(self.map_label(label))\n",
    "\n",
    "        # Convert to tensors; ensure correct shapes even when empty\n",
    "        if len(boxes) == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "        else:\n",
    "            boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def map_label(self, label):\n",
    "        raw = label.split(\"_\")[0].strip()\n",
    "        if raw.isalpha():\n",
    "            return 0\n",
    "\n",
    "        if raw.isdigit():\n",
    "            return 1\n",
    "\n",
    "        if raw in {\"+\", \"-\", \"=\", \"/\", \"*\", \"×\", \"÷\", \"^\"}:\n",
    "            return 2\n",
    "        return 3\n",
    "\n",
    "    def raw_label_to_id(self, raw):\n",
    "        if not hasattr(self, \"raw_vocab\"):\n",
    "            self.raw_vocab = {}\n",
    "        if raw not in self.raw_vocab:\n",
    "            self.raw_vocab[raw] = len(self.raw_vocab)\n",
    "        return self.raw_vocab[raw]\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2078b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../datas/FullExpressions/CROHME2019_train_png/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbad719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image :  torch.Size([3, 119, 500])\n",
      "Target :  {'boxes': tensor([[ 10.,  40.,  39., 108.],\n",
      "        [270.,  46., 320.,  72.],\n",
      "        [340.,  47., 371.,  71.],\n",
      "        [467.,  10., 489.,  38.],\n",
      "        [121.,  38., 166.,  63.],\n",
      "        [226.,  21., 265.,  65.],\n",
      "        [399.,  10., 452.,  76.]]), 'labels': tensor([0, 0, 2, 1, 2, 0, 0])}\n",
      "Dataset sizes -> total: 9993, train: 7994, val: 999, test: 1000\n"
     ]
    }
   ],
   "source": [
    "dataset = CROHMEDataset(\n",
    "    root=root,\n",
    "    transform=transforms.ToTensor(),\n",
    "    meta_classes=True\n",
    ")\n",
    "\n",
    "image, target = dataset[0]\n",
    "print(\"Image : \", image.size())\n",
    "print(\"Target : \", target)\n",
    "\n",
    "dataset_len = len(dataset)\n",
    "train_len = int(0.8 * dataset_len)\n",
    "val_len = int(0.1 * dataset_len)\n",
    "test_len = dataset_len - train_len - val_len\n",
    "\n",
    "train, val, test = torch.utils.data.random_split(\n",
    "    dataset, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "print(f\"Dataset sizes -> total: {dataset_len}, train: {train_len}, val: {val_len}, test: {test_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d8164",
   "metadata": {},
   "source": [
    "## Functions for visualization and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "234f693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"Load an image from file.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "def prepare_image(image, transform=None):\n",
    "    \"\"\"Prepare the image for model input.\"\"\"\n",
    "    if transform:\n",
    "        image = transform(image)\n",
    "    return image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "def visualize_predictions(image, boxes, labels, scores, threshold=0.4):\n",
    "    \"\"\"Visualize the bounding boxes and labels on the image.\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image.permute(1, 2, 0).numpy())\n",
    "\n",
    "    # Filter out boxes and labels below the threshold\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score >= threshold:\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            plt.gca().add_patch(plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,\n",
    "                                                fill=False, edgecolor='red', linewidth=3))\n",
    "            plt.text(x_min, y_min, f'{label.item()}: {score:.2f}', fontsize=12, color='red')\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d1ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU et mAP qui viennent d'Object_Segmentation\n",
    "\n",
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    \"\"\"\n",
    "    Calculates intersection over union\n",
    "\n",
    "    Parameters:\n",
    "        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
    "        boxes_labels (tensor): Correct Labels of Boxes (BATCH_SIZE, 4)\n",
    "        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n",
    "\n",
    "    Returns:\n",
    "        tensor: Intersection over union for all examples\n",
    "    \"\"\"\n",
    "\n",
    "    # Slicing idx:idx+1 in order to keep tensor dimensionality\n",
    "    # Doing ... in indexing if there would be additional dimensions\n",
    "    # Like for Yolo algorithm which would have (N, S, S, 4) in shape\n",
    "    if box_format == \"midpoint\":\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "\n",
    "    elif box_format == \"corners\":\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]\n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    # Need clamp(0) in case they do not intersect, then we want intersection to be 0\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)\n",
    "\n",
    "def mean_average_precision(\n",
    "    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"corners\", num_classes=20\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates mean average precision\n",
    "\n",
    "    Parameters:\n",
    "        pred_boxes (list): list of lists containing all bboxes with each bboxes\n",
    "        specified as [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n",
    "        true_boxes (list): Similar as pred_boxes except all the correct ones\n",
    "        iou_threshold (float): threshold where predicted bboxes is correct\n",
    "        box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n",
    "        num_classes (int): number of classes\n",
    "\n",
    "    Returns:\n",
    "        float: mAP value across all classes given a specific IoU threshold\n",
    "    \"\"\"\n",
    "\n",
    "    # list storing all AP for respective classes\n",
    "    average_precisions = []\n",
    "\n",
    "    # used for numerical stability later on\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        detections = []\n",
    "        ground_truths = []\n",
    "\n",
    "        # Go through all predictions and targets,\n",
    "        # and only add the ones that belong to the\n",
    "        # current class c\n",
    "        for detection in pred_boxes:\n",
    "            if detection[1] == c:\n",
    "                detections.append(detection)\n",
    "\n",
    "        for true_box in true_boxes:\n",
    "            if true_box[1] == c:\n",
    "                ground_truths.append(true_box)\n",
    "\n",
    "        # find the amount of bboxes for each training example\n",
    "        # Counter here finds how many ground truth bboxes we get\n",
    "        # for each training example, so let's say img 0 has 3,\n",
    "        # img 1 has 5 then we will obtain a dictionary with:\n",
    "        # amount_bboxes = {0:3, 1:5}\n",
    "        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
    "\n",
    "        # We then go through each key, val in this dictionary\n",
    "        # and convert to the following (w.r.t same example):\n",
    "        # ammount_bboxes = {0:torch.tensor[0,0,0], 1:torch.tensor[0,0,0,0,0]}\n",
    "        for key, val in amount_bboxes.items():\n",
    "            amount_bboxes[key] = torch.zeros(val)\n",
    "\n",
    "        # sort by box probabilities which is index 2\n",
    "        detections.sort(key=lambda x: x[2], reverse=True)\n",
    "        TP = torch.zeros((len(detections)))\n",
    "        FP = torch.zeros((len(detections)))\n",
    "        total_true_bboxes = len(ground_truths)\n",
    "\n",
    "        # If none exists for this class then we can safely skip\n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "\n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "            # Only take out the ground_truths that have the same\n",
    "            # training idx as detection\n",
    "            ground_truth_img = [\n",
    "                bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
    "            ]\n",
    "\n",
    "            num_gts = len(ground_truth_img)\n",
    "            best_iou = 0\n",
    "\n",
    "            for idx, gt in enumerate(ground_truth_img):\n",
    "                iou = intersection_over_union(\n",
    "                    torch.tensor(detection[3:]),\n",
    "                    torch.tensor(gt[3:]),\n",
    "                    box_format=box_format,\n",
    "                )\n",
    "\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = idx\n",
    "\n",
    "            if best_iou > iou_threshold:\n",
    "                # only detect ground truth detection once\n",
    "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "                    # true positive and add this bounding box to seen\n",
    "                    TP[detection_idx] = 1\n",
    "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "                else:\n",
    "                    FP[detection_idx] = 1\n",
    "\n",
    "            # if IOU is lower then the detection is a false positive\n",
    "            else:\n",
    "                FP[detection_idx] = 1\n",
    "\n",
    "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n",
    "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "        # torch.trapz for numerical integration\n",
    "        average_precisions.append(torch.trapz(precisions, recalls))\n",
    "\n",
    "    return sum(average_precisions) / len(average_precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4840a57",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87a580f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone frozen. Only the RPN and heads will be trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   3%|▎         | 75/2665 [00:52<29:57,  1.44it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     85\u001b[39m optimizer.zero_grad()\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m loss_dict = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# Compute total loss\u001b[39;00m\n\u001b[32m     91\u001b[39m losses = \u001b[38;5;28msum\u001b[39m(loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m loss_dict.values())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages/torchvision/models/detection/generalized_rcnn.py:117\u001b[39m, in \u001b[36mGeneralizedRCNN.forward\u001b[39m\u001b[34m(self, images, targets)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch.Tensor):\n\u001b[32m    116\u001b[39m     features = OrderedDict([(\u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m, features)])\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m proposals, proposal_losses = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrpn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m detections, detector_losses = \u001b[38;5;28mself\u001b[39m.roi_heads(features, proposals, images.image_sizes, targets)\n\u001b[32m    119\u001b[39m detections = \u001b[38;5;28mself\u001b[39m.transform.postprocess(\n\u001b[32m    120\u001b[39m     detections, images.image_sizes, original_image_sizes\n\u001b[32m    121\u001b[39m )  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages/torchvision/models/detection/rpn.py:370\u001b[39m, in \u001b[36mRegionProposalNetwork.forward\u001b[39m\u001b[34m(self, images, features, targets)\u001b[39m\n\u001b[32m    366\u001b[39m objectness, pred_bbox_deltas = concat_box_prediction_layers(objectness, pred_bbox_deltas)\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m# apply pred_bbox_deltas to anchors to obtain the decoded proposals\u001b[39;00m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# note that we detach the deltas because Faster R-CNN do not backprop through\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# the proposals\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m proposals = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbox_coder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_bbox_deltas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m proposals = proposals.view(num_images, -\u001b[32m1\u001b[39m, \u001b[32m4\u001b[39m)\n\u001b[32m    372\u001b[39m boxes, scores = \u001b[38;5;28mself\u001b[39m.filter_proposals(proposals, objectness, images.image_sizes, num_anchors_per_level)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages/torchvision/models/detection/_utils.py:178\u001b[39m, in \u001b[36mBoxCoder.decode\u001b[39m\u001b[34m(self, rel_codes, boxes)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m box_sum > \u001b[32m0\u001b[39m:\n\u001b[32m    177\u001b[39m     rel_codes = rel_codes.reshape(box_sum, -\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m pred_boxes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecode_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel_codes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_boxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m box_sum > \u001b[32m0\u001b[39m:\n\u001b[32m    180\u001b[39m     pred_boxes = pred_boxes.reshape(box_sum, -\u001b[32m1\u001b[39m, \u001b[32m4\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages/torchvision/models/detection/_utils.py:216\u001b[39m, in \u001b[36mBoxCoder.decode_single\u001b[39m\u001b[34m(self, rel_codes, boxes)\u001b[39m\n\u001b[32m    213\u001b[39m pred_h = torch.exp(dh) * heights[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# Distance from center to box's corner.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m c_to_c_h = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_ctr_y\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_h\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m * pred_h\n\u001b[32m    217\u001b[39m c_to_c_w = torch.tensor(\u001b[32m0.5\u001b[39m, dtype=pred_ctr_x.dtype, device=pred_w.device) * pred_w\n\u001b[32m    219\u001b[39m pred_boxes1 = pred_ctr_x - c_to_c_w\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 3\n",
    "learning_rate =0.0008\n",
    "batch_size = 3\n",
    "# Keep val_size if you want an absolute val count fallback, but we'll use dynamic splits\n",
    "val_size = 10\n",
    "\n",
    "val_err_array = np.array([])\n",
    "train_err_array = np.array([])\n",
    "nb_sample_array = np.array([])\n",
    "train_loss_classifier_array = np.array([])\n",
    "train_loss_objectness_array = np.array([])\n",
    "\n",
    "# Early stopping parameters\n",
    "patience =5\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Use the Subset objects created earlier by random_split: `train`, `val`, `test`.\n",
    "# If `train` or `val` don't exist yet (cell not executed), compute splits here as a fallback.\n",
    "try:\n",
    "    train_subset = train\n",
    "    val_subset = val\n",
    "except NameError:\n",
    "    dataset_len = len(dataset)\n",
    "    train_len = int(0.8 * dataset_len)\n",
    "    val_len = int(0.1 * dataset_len)\n",
    "    test_len = dataset_len - train_len - val_len\n",
    "    train_subset, val_subset, _ = torch.utils.data.random_split(dataset, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# Load a pretrained Faster R-CNN model\n",
    "#model = detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "#model = detection.ssd300_vgg16(weights=\"DEFAULT\")\n",
    "model = detection.fasterrcnn_mobilenet_v3_large_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "# Set the requires_grad attribute of all the backbone parameters to False\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\"Backbone frozen. Only the RPN and heads will be trained.\")\n",
    "\n",
    "# Modify the model for the number of classes\n",
    "num_classes = 5  # 20 classes + background\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Set up the optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=learning_rate, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Function for validation\n",
    "def validate(model, val_loader):\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            val_loss += losses.item()\n",
    "\n",
    "    return val_loss / len(val_loader)\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')  # Initialize best validation loss\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_loss_classifier = 0.0\n",
    "    epoch_loss_objectness = 0.0\n",
    "    model.train()  # Set the model to training mode\n",
    "    nb_used_sample = 0 # Initialize the number of samples used in this epoch\n",
    "\n",
    "    for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        # Move images and targets to the device (GPU or CPU)\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        # Compute total loss\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # Backward pass\n",
    "        losses.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        epoch_loss += losses.item()\n",
    "        # Use .get to avoid KeyError if a particular loss term is missing\n",
    "        epoch_loss_classifier += loss_dict.get('loss_classifier', torch.tensor(0.0)).item()\n",
    "        epoch_loss_objectness += loss_dict.get('loss_objectness', torch.tensor(0.0)).item()\n",
    "        nb_used_sample += len(images)\n",
    "\n",
    "\n",
    "################ FOR VGG16 ###############\n",
    "    #     # Accumulate loss - Use keys appropriate for SSD\n",
    "    #     epoch_loss += losses.item()\n",
    "    #     # Assuming loss_dict for SSD contains 'classification' and 'bbox_regression'\n",
    "    #     if 'classification' in loss_dict:\n",
    "    #         epoch_loss_classifier += loss_dict['classification'].item()\n",
    "    #     if 'bbox_regression' in loss_dict:\n",
    "    #          epoch_loss_objectness += loss_dict['bbox_regression'].item() # Using objectness for regression loss here\n",
    "    #     nb_used_sample += batch_size\n",
    "\n",
    "\n",
    "    # # Calculate average training loss for the epoch\n",
    "    # train_err = epoch_loss / len(train_loader)\n",
    "    # # Calculate average for classifier and regression losses only if they were accumulated\n",
    "    # train_loss_classifier = epoch_loss_classifier / len(train_loader) if 'classification' in loss_dict else 0\n",
    "    # train_loss_objectness = epoch_loss_objectness / len(train_loader) if 'bbox_regression' in loss_dict else 0\n",
    "###########################################\n",
    "\n",
    "\n",
    "    # Calculate average training loss for the epoch\n",
    "    train_err = epoch_loss / len(train_loader)\n",
    "    train_loss_classifier = epoch_loss_classifier / len(train_loader) if len(train_loader) > 0 else 0.0\n",
    "    train_loss_objectness = epoch_loss_objectness / len(train_loader) if len(train_loader) > 0 else 0.0\n",
    "\n",
    "    # Print epoch loss\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {train_err:.4f}, Classifier Loss: {train_loss_classifier:.4f}, Objectness Loss: {train_loss_objectness:.4f}\")\n",
    "\n",
    "    # Validate after each epoch\n",
    "    val_loss = validate(model, val_loader)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    train_err_array = np.append(train_err_array, train_err)\n",
    "    val_err_array = np.append(val_err_array, val_loss)\n",
    "    nb_sample_array = np.append(nb_sample_array, nb_used_sample)\n",
    "    train_loss_classifier_array = np.append(train_loss_classifier_array, train_loss_classifier)\n",
    "    train_loss_objectness_array = np.append(train_loss_objectness_array, train_loss_objectness)\n",
    "\n",
    "    # Save the model weights if validation loss has improved\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'faster_rcnn_voc_best.pth')\n",
    "        print(f\"Model weights saved. New best validation loss: {best_val_loss:.4f}\")\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping after {patience} epochs without improvement.\")\n",
    "        break\n",
    "\n",
    "# Final message\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU et mAP qui viennent d'Object_Segmentation\n",
    "\n",
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    \"\"\"\n",
    "    Calculates intersection over union\n",
    "\n",
    "    Parameters:\n",
    "        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
    "        boxes_labels (tensor): Correct Labels of Boxes (BATCH_SIZE, 4)\n",
    "        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n",
    "\n",
    "    Returns:\n",
    "        tensor: Intersection over union for all examples\n",
    "    \"\"\"\n",
    "\n",
    "    if box_format == \"midpoint\":\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "\n",
    "    elif box_format == \"corners\":\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]\n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    # Need clamp(0) in case they do not intersect, then we want intersection to be 0\n",
    "    intersection = (x2 - x1).clamp(min=0) * (y2 - y1).clamp(min=0)\n",
    "    box1_area = (box1_x2 - box1_x1).abs() * (box1_y2 - box1_y1).abs()\n",
    "    box2_area = (box2_x2 - box2_x1).abs() * (box2_y2 - box2_y1).abs()\n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)\n",
    "\n",
    "\n",
    "def mean_average_precision(\n",
    "    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"corners\", num_classes=20\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates mean average precision\n",
    "\n",
    "    Parameters:\n",
    "        pred_boxes (list): list of lists containing all bboxes with each bboxes\n",
    "        specified as [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n",
    "        true_boxes (list): Similar as pred_boxes except all the correct ones\n",
    "        iou_threshold (float): threshold where predicted bboxes is correct\n",
    "        box_format (str): \"midpoint\" or \"corners\" used to specify bboxes\n",
    "        num_classes (int): number of classes\n",
    "\n",
    "    Returns:\n",
    "        float: mAP value across all classes given a specific IoU threshold\n",
    "    \"\"\"\n",
    "\n",
    "    average_precisions = []\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        detections = []\n",
    "        ground_truths = []\n",
    "\n",
    "        # Collect detections and ground truths for class c\n",
    "        for detection in pred_boxes:\n",
    "            # detection[1] may be int or tensor-like\n",
    "            if int(detection[1]) == c:\n",
    "                detections.append(detection)\n",
    "\n",
    "        for true_box in true_boxes:\n",
    "            if int(true_box[1]) == c:\n",
    "                ground_truths.append(true_box)\n",
    "\n",
    "        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
    "\n",
    "        for key, val in amount_bboxes.items():\n",
    "            amount_bboxes[key] = torch.zeros(val)\n",
    "\n",
    "        # sort by confidence score (index 2)\n",
    "        detections.sort(key=lambda x: x[2], reverse=True)\n",
    "        TP = torch.zeros((len(detections)))\n",
    "        FP = torch.zeros((len(detections)))\n",
    "        total_true_bboxes = len(ground_truths)\n",
    "\n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "\n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "            # Ground truths for the same image index\n",
    "            ground_truth_img = [bbox for bbox in ground_truths if bbox[0] == detection[0]]\n",
    "\n",
    "            best_iou = 0.0\n",
    "            best_gt_idx = -1\n",
    "\n",
    "            for idx, gt in enumerate(ground_truth_img):\n",
    "                # Compute IoU and convert to float for safe comparisons\n",
    "                iou_tensor = intersection_over_union(\n",
    "                    torch.tensor(detection[3:], dtype=torch.float32),\n",
    "                    torch.tensor(gt[3:], dtype=torch.float32),\n",
    "                    box_format=box_format,\n",
    "                )\n",
    "                iou = float(iou_tensor.item()) if torch.is_tensor(iou_tensor) else float(iou_tensor)\n",
    "\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = idx\n",
    "\n",
    "            if best_iou > iou_threshold:\n",
    "                # only detect ground truth once\n",
    "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "                    TP[detection_idx] = 1\n",
    "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "                else:\n",
    "                    FP[detection_idx] = 1\n",
    "            else:\n",
    "                FP[detection_idx] = 1\n",
    "\n",
    "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n",
    "\n",
    "        # Ensure tensors are float and prepend start points for integration\n",
    "        precisions = torch.cat((torch.tensor([1.0]), precisions))\n",
    "        recalls = torch.cat((torch.tensor([0.0]), recalls))\n",
    "\n",
    "        # Numerical integration (area under precision-recall curve)\n",
    "        ap = float(torch.trapz(precisions, recalls).item())\n",
    "        average_precisions.append(ap)\n",
    "\n",
    "    if len(average_precisions) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return sum(average_precisions) / len(average_precisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1719a56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pix2text not found — installing via python -m pip\n",
      "Collecting pix2text>=1.1\n",
      "  Downloading pix2text-1.1.4-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pix2text>=1.1\n",
      "  Downloading pix2text-1.1.4-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting click (from pix2text>=1.1)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: tqdm in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pix2text>=1.1) (4.67.1)\n",
      "Requirement already satisfied: numpy in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pix2text>=1.1) (2.3.5)\n",
      "Collecting click (from pix2text>=1.1)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: tqdm in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pix2text>=1.1) (4.67.1)\n",
      "Requirement already satisfied: numpy in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pix2text>=1.1) (2.3.5)\n",
      "Collecting opencv-python (from pix2text>=1.1)\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting cnocr>=2.3.0.2 (from cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading cnocr-2.3.2.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting opencv-python (from pix2text>=1.1)\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting cnocr>=2.3.0.2 (from cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading cnocr-2.3.2.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting cnstd>=1.2.4.2 (from pix2text>=1.1)\n",
      "  Downloading cnstd-1.2.6.1-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: pillow in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pix2text>=1.1) (12.0.0)\n",
      "Requirement already satisfied: torch in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pix2text>=1.1) (2.9.1)\n",
      "Requirement already satisfied: torchvision in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pix2text>=1.1) (0.24.1)\n",
      "Collecting transformers>=4.37.0 (from pix2text>=1.1)\n",
      "Collecting cnstd>=1.2.4.2 (from pix2text>=1.1)\n",
      "  Downloading cnstd-1.2.6.1-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: pillow in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pix2text>=1.1) (12.0.0)\n",
      "Requirement already satisfied: torch in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pix2text>=1.1) (2.9.1)\n",
      "Requirement already satisfied: torchvision in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pix2text>=1.1) (0.24.1)\n",
      "Collecting transformers>=4.37.0 (from pix2text>=1.1)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting optimum[onnxruntime] (from pix2text>=1.1)\n",
      "  Downloading optimum-2.0.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting optimum[onnxruntime] (from pix2text>=1.1)\n",
      "  Downloading optimum-2.0.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting PyMuPDF (from pix2text>=1.1)\n",
      "  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting pyspellchecker (from pix2text>=1.1)\n",
      "  Downloading pyspellchecker-0.8.4-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting PyMuPDF (from pix2text>=1.1)\n",
      "  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting pyspellchecker (from pix2text>=1.1)\n",
      "  Downloading pyspellchecker-0.8.4-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting doclayout-yolo<0.1 (from pix2text>=1.1)\n",
      "  Downloading doclayout_yolo-0.0.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from doclayout-yolo<0.1->pix2text>=1.1) (3.10.7)\n",
      "Collecting pyyaml>=5.3.1 (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting doclayout-yolo<0.1 (from pix2text>=1.1)\n",
      "  Downloading doclayout_yolo-0.0.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from doclayout-yolo<0.1->pix2text>=1.1) (3.10.7)\n",
      "Collecting pyyaml>=5.3.1 (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting requests>=2.23.0 (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from doclayout-yolo<0.1->pix2text>=1.1) (1.16.3)\n",
      "Requirement already satisfied: psutil in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from doclayout-yolo<0.1->pix2text>=1.1) (7.1.3)\n",
      "Collecting py-cpuinfo (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting requests>=2.23.0 (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from doclayout-yolo<0.1->pix2text>=1.1) (1.16.3)\n",
      "Requirement already satisfied: psutil in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from doclayout-yolo<0.1->pix2text>=1.1) (7.1.3)\n",
      "Collecting py-cpuinfo (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting thop>=0.1.1 (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from doclayout-yolo<0.1->pix2text>=1.1) (2.3.3)\n",
      "Collecting seaborn>=0.11.0 (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting albumentations>=1.4.11 (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting thop>=0.1.1 (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from doclayout-yolo<0.1->pix2text>=1.1) (2.3.3)\n",
      "Collecting seaborn>=0.11.0 (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting albumentations>=1.4.11 (from doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting pydantic>=2.9.2 (from albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting albucore==0.0.24 (from albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pydantic>=2.9.2 (from albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting albucore==0.0.24 (from albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading stringzilla-4.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (110 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading stringzilla-4.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (110 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading simsimd-6.5.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (70 kB)\n",
      "Collecting pytorch-lightning>=2.0.0 (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading simsimd-6.5.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (70 kB)\n",
      "Collecting pytorch-lightning>=2.0.0 (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting wandb (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading wandb-0.23.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting torchmetrics (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting wandb (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading wandb-0.23.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting torchmetrics (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting onnx (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading onnx-1.20.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting rapidocr>=3.0 (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading rapidocr-3.4.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting onnx (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading onnx-1.20.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting rapidocr>=3.0 (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading rapidocr-3.4.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting onnxruntime (from cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting unidecode (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting onnxruntime (from cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting unidecode (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting shapely (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading shapely-2.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pyclipper (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading pyclipper-1.4.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.6 kB)\n",
      "Collecting shapely (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading shapely-2.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pyclipper (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading pyclipper-1.4.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.6 kB)\n",
      "Collecting huggingface-hub (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading huggingface_hub-1.1.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting huggingface-hub (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading huggingface_hub-1.1.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting ultralytics (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading ultralytics-8.3.234-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (2.9.0.post0)\n",
      "Collecting ultralytics (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading ultralytics-8.3.234-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (2.9.0.post0)\n",
      "Collecting numpy (from pix2text>=1.1)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pandas>=1.1.4->doclayout-yolo<0.1->pix2text>=1.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pandas>=1.1.4->doclayout-yolo<0.1->pix2text>=1.1) (2025.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting numpy (from pix2text>=1.1)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pandas>=1.1.4->doclayout-yolo<0.1->pix2text>=1.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pandas>=1.1.4->doclayout-yolo<0.1->pix2text>=1.1) (2025.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.9.2->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.9.2->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (1.17.0)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1) (2025.10.0)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.9.2->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.9.2->albumentations>=1.4.11->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->doclayout-yolo<0.1->pix2text>=1.1) (1.17.0)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1) (2025.10.0)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: setuptools in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1) (65.5.0)\n",
      "Collecting omegaconf (from rapidocr>=3.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: setuptools in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1) (65.5.0)\n",
      "Collecting omegaconf (from rapidocr>=3.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting colorlog (from rapidocr>=3.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting colorlog (from rapidocr>=3.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.23.0->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.23.0->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.23.0->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: filelock in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (3.5.1)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.23.0->doclayout-yolo<0.1->pix2text>=1.1)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: filelock in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from torch->pix2text>=1.1) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from sympy>=1.13.3->torch->pix2text>=1.1) (1.3.0)\n",
      "Collecting huggingface-hub (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from sympy>=1.13.3->torch->pix2text>=1.1) (1.3.0)\n",
      "Collecting huggingface-hub (from cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.37.0->pix2text>=1.1)\n",
      "  Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.37.0->pix2text>=1.1)\n",
      "  Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.37.0->pix2text>=1.1)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.37.0->pix2text>=1.1)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.37.0->pix2text>=1.1)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.37.0->pix2text>=1.1)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub->cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from jinja2->torch->pix2text>=1.1) (3.0.3)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->rapidocr>=3.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub->cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from jinja2->torch->pix2text>=1.1) (3.0.3)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->rapidocr>=3.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Installing build dependencies: started\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting protobuf>=4.25.1 (from onnx->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting ml_dtypes>=0.5.0 (from onnx->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting protobuf>=4.25.1 (from onnx->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting ml_dtypes>=0.5.0 (from onnx->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting coloredlogs (from onnxruntime->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting coloredlogs (from onnxruntime->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting optimum-onnx[onnxruntime] (from optimum[onnxruntime]->pix2text>=1.1)\n",
      "  Downloading optimum_onnx-0.0.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting optimum-onnx[onnxruntime] (from optimum[onnxruntime]->pix2text>=1.1)\n",
      "  Downloading optimum_onnx-0.0.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting transformers>=4.37.0 (from pix2text>=1.1)\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting transformers>=4.37.0 (from pix2text>=1.1)\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.37.0->pix2text>=1.1)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.37.0->pix2text>=1.1)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting polars>=0.20.0 (from ultralytics->cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading polars-1.35.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting ultralytics-thop>=2.0.18 (from ultralytics->cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting polars>=0.20.0 (from ultralytics->cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading polars-1.35.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting ultralytics-thop>=2.0.18 (from ultralytics->cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting polars-runtime-32==1.35.2 (from polars>=0.20.0->ultralytics->cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading polars_runtime_32-1.35.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "Collecting polars-runtime-32==1.35.2 (from polars>=0.20.0->ultralytics->cnstd>=1.2.4.2->pix2text>=1.1)\n",
      "  Downloading polars_runtime_32-1.35.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1) (4.5.0)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /home/raclax/Documents/M2/Part2/DL2/Project/deepl/lib/python3.11/site-packages (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1) (4.5.0)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading sentry_sdk-2.46.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading sentry_sdk-2.46.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading pix2text-1.1.4-py3-none-any.whl (231 kB)\n",
      "Downloading doclayout_yolo-0.0.4-py3-none-any.whl (711 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/711.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text>=1.1)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading pix2text-1.1.4-py3-none-any.whl (231 kB)\n",
      "Downloading doclayout_yolo-0.0.4-py3-none-any.whl (711 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m711.3/711.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "Downloading albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Downloading cnocr-2.3.2.2-py3-none-any.whl (225 kB)\n",
      "Downloading cnstd-1.2.6.1-py3-none-any.whl (254 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m711.3/711.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "Downloading albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Downloading cnocr-2.3.2.2-py3-none-any.whl (225 kB)\n",
      "Downloading cnstd-1.2.6.1-py3-none-any.whl (254 kB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mUsing cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:18\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:18\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (365 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (365 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (210 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (210 kB)\n",
      "Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/806.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.6/806.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rapidocr-3.4.2-py3-none-any.whl (15.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.6/806.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rapidocr-3.4.2-py3-none-any.whl (15.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyclipper-1.4.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (989 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyclipper-1.4.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (989 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.6/989.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.6/989.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading shapely-2.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.1 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mUsing cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading shapely-2.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading simsimd-6.5.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading simsimd-6.5.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading stringzilla-4.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (842 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/842.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading stringzilla-4.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (842 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m842.5/842.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m842.5/842.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.4/800.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.4/800.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading onnx-1.20.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/18.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading onnx-1.20.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading optimum-2.0.0-py3-none-any.whl (162 kB)\n",
      "Downloading optimum_onnx-0.0.3-py3-none-any.whl (192 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading optimum-2.0.0-py3-none-any.whl (162 kB)\n",
      "Downloading optimum_onnx-0.0.3-py3-none-any.whl (192 kB)\n",
      "Downloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/11.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyspellchecker-0.8.4-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyspellchecker-0.8.4-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics-8.3.234-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics-8.3.234-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading polars-1.35.2-py3-none-any.whl (783 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading polars-1.35.2-py3-none-any.whl (783 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m783.6/783.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading polars_runtime_32-1.35.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m783.6/783.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading polars_runtime_32-1.35.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:14\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
      "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:14\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
      "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
      "Downloading wandb-0.23.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.2 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/20.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading wandb-0.23.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sentry_sdk-2.46.0-py2.py3-none-any.whl (406 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sentry_sdk-2.46.0-py2.py3-none-any.whl (406 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml): started\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml): started\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=817e09c2c138a1873382606e468858287ea322afe23853525bb069b391604b52\n",
      "  Stored in directory: /home/raclax/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "Successfully built antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=817e09c2c138a1873382606e468858287ea322afe23853525bb069b391604b52\n",
      "  Stored in directory: /home/raclax/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: simsimd, py-cpuinfo, flatbuffers, antlr4-python3-runtime, urllib3, unidecode, typing-inspection, stringzilla, smmap, safetensors, regex, pyyaml, pyspellchecker, PyMuPDF, pydantic-core, pyclipper, protobuf, propcache, polars-runtime-32, numpy, multidict, lightning-utilities, idna, humanfriendly, hf-xet, frozenlist, colorlog, click, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, shapely, sentry-sdk, requests, pydantic, polars, opencv-python-headless, opencv-python, omegaconf, ml_dtypes, gitdb, coloredlogs, aiosignal, rapidocr, onnxruntime, onnx, huggingface-hub, gitpython, albucore, aiohttp, wandb, ultralytics-thop, torchmetrics, tokenizers, thop, seaborn, albumentations, ultralytics, transformers, pytorch-lightning, doclayout-yolo, optimum, cnstd, optimum-onnx, cnocr, pix2text\n",
      "\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/69\u001b[0m [flatbuffers]Installing collected packages: simsimd, py-cpuinfo, flatbuffers, antlr4-python3-runtime, urllib3, unidecode, typing-inspection, stringzilla, smmap, safetensors, regex, pyyaml, pyspellchecker, PyMuPDF, pydantic-core, pyclipper, protobuf, propcache, polars-runtime-32, numpy, multidict, lightning-utilities, idna, humanfriendly, hf-xet, frozenlist, colorlog, click, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, shapely, sentry-sdk, requests, pydantic, polars, opencv-python-headless, opencv-python, omegaconf, ml_dtypes, gitdb, coloredlogs, aiosignal, rapidocr, onnxruntime, onnx, huggingface-hub, gitpython, albucore, aiohttp, wandb, ultralytics-thop, torchmetrics, tokenizers, thop, seaborn, albumentations, ultralytics, transformers, pytorch-lightning, doclayout-yolo, optimum, cnstd, optimum-onnx, cnocr, pix2text\n",
      "\u001b[2K  Attempting uninstall: numpy[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/69\u001b[0m [polars-runtime-32]time]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.5━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/69\u001b[0m [polars-runtime-32]\n",
      "\u001b[2K    Uninstalling numpy-2.3.5:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/69\u001b[0m [numpy]time-32]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.5━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/69\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: numpy\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/69\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.5━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/69\u001b[0m [polars-runtime-32]\n",
      "\u001b[2K    Uninstalling numpy-2.3.5:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/69\u001b[0m [numpy]time-32]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.5━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/69\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69/69\u001b[0m [pix2text]pix2text]cnocr]m-onnx]o]ng]less]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyMuPDF-1.26.6 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 albucore-0.0.24 albumentations-2.0.8 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 attrs-25.4.0 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 cnocr-2.3.2.2 cnstd-1.2.6.1 coloredlogs-15.0.1 colorlog-6.10.1 doclayout-yolo-0.0.4 flatbuffers-25.9.23 frozenlist-1.8.0 gitdb-4.0.12 gitpython-3.1.45 hf-xet-1.2.0 huggingface-hub-0.36.0 humanfriendly-10.0 idna-3.11 lightning-utilities-0.15.2 ml_dtypes-0.5.4 multidict-6.7.0 numpy-2.2.6 omegaconf-2.3.0 onnx-1.20.0 onnxruntime-1.23.2 opencv-python-4.12.0.88 opencv-python-headless-4.12.0.88 optimum-2.0.0 optimum-onnx-0.0.3 pix2text-1.1.4 polars-1.35.2 polars-runtime-32-1.35.2 propcache-0.4.1 protobuf-6.33.1 py-cpuinfo-9.0.0 pyclipper-1.4.0 pydantic-2.12.5 pydantic-core-2.41.5 pyspellchecker-0.8.4 pytorch-lightning-2.6.0 pyyaml-6.0.3 rapidocr-3.4.2 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 seaborn-0.13.2 sentry-sdk-2.46.0 shapely-2.1.2 simsimd-6.5.3 smmap-5.0.2 stringzilla-4.4.0 thop-0.1.1.post2209072238 tokenizers-0.21.4 torchmetrics-1.8.2 transformers-4.55.4 typing-inspection-0.4.2 ultralytics-8.3.234 ultralytics-thop-2.0.18 unidecode-1.4.0 urllib3-2.5.0 wandb-0.23.0 yarl-1.22.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69/69\u001b[0m [pix2text]pix2text]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyMuPDF-1.26.6 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 albucore-0.0.24 albumentations-2.0.8 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 attrs-25.4.0 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 cnocr-2.3.2.2 cnstd-1.2.6.1 coloredlogs-15.0.1 colorlog-6.10.1 doclayout-yolo-0.0.4 flatbuffers-25.9.23 frozenlist-1.8.0 gitdb-4.0.12 gitpython-3.1.45 hf-xet-1.2.0 huggingface-hub-0.36.0 humanfriendly-10.0 idna-3.11 lightning-utilities-0.15.2 ml_dtypes-0.5.4 multidict-6.7.0 numpy-2.2.6 omegaconf-2.3.0 onnx-1.20.0 onnxruntime-1.23.2 opencv-python-4.12.0.88 opencv-python-headless-4.12.0.88 optimum-2.0.0 optimum-onnx-0.0.3 pix2text-1.1.4 polars-1.35.2 polars-runtime-32-1.35.2 propcache-0.4.1 protobuf-6.33.1 py-cpuinfo-9.0.0 pyclipper-1.4.0 pydantic-2.12.5 pydantic-core-2.41.5 pyspellchecker-0.8.4 pytorch-lightning-2.6.0 pyyaml-6.0.3 rapidocr-3.4.2 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 seaborn-0.13.2 sentry-sdk-2.46.0 shapely-2.1.2 simsimd-6.5.3 smmap-5.0.2 stringzilla-4.4.0 thop-0.1.1.post2209072238 tokenizers-0.21.4 torchmetrics-1.8.2 transformers-4.55.4 typing-inspection-0.4.2 ultralytics-8.3.234 ultralytics-thop-2.0.18 unidecode-1.4.0 urllib3-2.5.0 wandb-0.23.0 yarl-1.22.0\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/home/raclax/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/home/raclax/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "pix2text is available\n",
      "pix2text is available\n"
     ]
    }
   ],
   "source": [
    "# Secondary installation attempt kept robust: use python -m pip to avoid broken pip binary\n",
    "import sys, subprocess\n",
    "try:\n",
    "    import pix2text\n",
    "except Exception:\n",
    "    print('pix2text not found — installing via python -m pip')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pix2text>=1.1'])\n",
    "    import pix2text\n",
    "print('pix2text is available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f962bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2025-12-02 15:21:36,471 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,473 [RapidOCR] main.py:53: Using /home/raclax/.cnstd/1.2/ppocr/ch_PP-OCRv5_det/ch_PP-OCRv5_det_infer.onnx\u001b[0m\n",
      "\u001b[33m[WARNING] 2025-12-02 15:21:36,475 [RapidOCR] provider_config.py:93: CUDAExecutionProvider is not in available providers (['AzureExecutionProvider', 'CPUExecutionProvider']). Use AzureExecutionProvider inference by default.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,476 [RapidOCR] provider_config.py:168: If you want to use CUDAExecutionProvider acceleration, you must do:(For reference only) If you want to use GPU acceleration, you must do:\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,477 [RapidOCR] provider_config.py:168: First, uninstall all onnxruntime packages in current environment.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,478 [RapidOCR] provider_config.py:168: Second, install onnxruntime-gpu by `pip install onnxruntime-gpu`.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,479 [RapidOCR] provider_config.py:168: Note the onnxruntime-gpu version must match your cuda and cudnn version.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,480 [RapidOCR] provider_config.py:168: You can refer this link: https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,482 [RapidOCR] provider_config.py:168: Third, ensure CUDAExecutionProvider is in available providers list. e.g. ['CUDAExecutionProvider', 'CPUExecutionProvider']\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,473 [RapidOCR] main.py:53: Using /home/raclax/.cnstd/1.2/ppocr/ch_PP-OCRv5_det/ch_PP-OCRv5_det_infer.onnx\u001b[0m\n",
      "\u001b[33m[WARNING] 2025-12-02 15:21:36,475 [RapidOCR] provider_config.py:93: CUDAExecutionProvider is not in available providers (['AzureExecutionProvider', 'CPUExecutionProvider']). Use AzureExecutionProvider inference by default.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,476 [RapidOCR] provider_config.py:168: If you want to use CUDAExecutionProvider acceleration, you must do:(For reference only) If you want to use GPU acceleration, you must do:\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,477 [RapidOCR] provider_config.py:168: First, uninstall all onnxruntime packages in current environment.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,478 [RapidOCR] provider_config.py:168: Second, install onnxruntime-gpu by `pip install onnxruntime-gpu`.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,479 [RapidOCR] provider_config.py:168: Note the onnxruntime-gpu version must match your cuda and cudnn version.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,480 [RapidOCR] provider_config.py:168: You can refer this link: https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,482 [RapidOCR] provider_config.py:168: Third, ensure CUDAExecutionProvider is in available providers list. e.g. ['CUDAExecutionProvider', 'CPUExecutionProvider']\u001b[0m\n",
      "\u001b[33m[WARNING] 2025-12-02 15:21:36,619 [RapidOCR] provider_config.py:93: CUDAExecutionProvider is not in available providers (['AzureExecutionProvider', 'CPUExecutionProvider']). Use AzureExecutionProvider inference by default.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,621 [RapidOCR] provider_config.py:168: If you want to use CUDAExecutionProvider acceleration, you must do:(For reference only) If you want to use GPU acceleration, you must do:\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,622 [RapidOCR] provider_config.py:168: First, uninstall all onnxruntime packages in current environment.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,623 [RapidOCR] provider_config.py:168: Second, install onnxruntime-gpu by `pip install onnxruntime-gpu`.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,624 [RapidOCR] provider_config.py:168: Note the onnxruntime-gpu version must match your cuda and cudnn version.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,625 [RapidOCR] provider_config.py:168: You can refer this link: https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,627 [RapidOCR] provider_config.py:168: Third, ensure CUDAExecutionProvider is in available providers list. e.g. ['CUDAExecutionProvider', 'CPUExecutionProvider']\u001b[0m\n",
      "\u001b[33m[WARNING] 2025-12-02 15:21:36,619 [RapidOCR] provider_config.py:93: CUDAExecutionProvider is not in available providers (['AzureExecutionProvider', 'CPUExecutionProvider']). Use AzureExecutionProvider inference by default.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,621 [RapidOCR] provider_config.py:168: If you want to use CUDAExecutionProvider acceleration, you must do:(For reference only) If you want to use GPU acceleration, you must do:\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,622 [RapidOCR] provider_config.py:168: First, uninstall all onnxruntime packages in current environment.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,623 [RapidOCR] provider_config.py:168: Second, install onnxruntime-gpu by `pip install onnxruntime-gpu`.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,624 [RapidOCR] provider_config.py:168: Note the onnxruntime-gpu version must match your cuda and cudnn version.\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,625 [RapidOCR] provider_config.py:168: You can refer this link: https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:36,627 [RapidOCR] provider_config.py:168: Third, ensure CUDAExecutionProvider is in available providers list. e.g. ['CUDAExecutionProvider', 'CPUExecutionProvider']\u001b[0m\n",
      "Could not find any ONNX files with standard file name decoder_model_merged.onnx, files found: [PosixPath('decoder_model.onnx'), PosixPath('encoder_model.onnx')]. Please make sure to pass a `file_name` and/or `subfolder` argument to `from_pretrained` when loading an ONNX file with non-standard file names.\n",
      "Could not find any ONNX files with standard file name decoder_model_merged.onnx, files found: [PosixPath('decoder_model.onnx'), PosixPath('encoder_model.onnx')]. Please make sure to pass a `file_name` and/or `subfolder` argument to `from_pretrained` when loading an ONNX file with non-standard file names.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU initialization failed (will fall back to CPU): Asked to use CUDAExecutionProvider as an ONNX Runtime execution provider, but the available execution providers are ['AzureExecutionProvider', 'CPUExecutionProvider'].\n",
      "Initializing Pix2Text on CPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2025-12-02 15:21:37,737 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:37,739 [RapidOCR] main.py:53: Using /home/raclax/.cnstd/1.2/ppocr/ch_PP-OCRv5_det/ch_PP-OCRv5_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-12-02 15:21:37,739 [RapidOCR] main.py:53: Using /home/raclax/.cnstd/1.2/ppocr/ch_PP-OCRv5_det/ch_PP-OCRv5_det_infer.onnx\u001b[0m\n",
      "Could not find any ONNX files with standard file name decoder_model_merged.onnx, files found: [PosixPath('decoder_model.onnx'), PosixPath('encoder_model.onnx')]. Please make sure to pass a `file_name` and/or `subfolder` argument to `from_pretrained` when loading an ONNX file with non-standard file names.\n",
      "Could not find any ONNX files with standard file name decoder_model_merged.onnx, files found: [PosixPath('decoder_model.onnx'), PosixPath('encoder_model.onnx')]. Please make sure to pass a `file_name` and/or `subfolder` argument to `from_pretrained` when loading an ONNX file with non-standard file names.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pix2Text initialized on CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=A x+A^{2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pix2text import Pix2Text\n",
    "\n",
    "# Initialize Pix2Text: try GPU first, fall back to CPU if ONNX Runtime doesn't expose CUDAExecutionProvider\n",
    "try:\n",
    "    p2t = Pix2Text.from_config(device='cuda')  # attempt GPU/ONNXRuntime CUDAExecutionProvider\n",
    "    print('Pix2Text initialized on CUDA device')\n",
    "except Exception as e:\n",
    "    # Common failure: onnxruntime not built with GPU support -> ValueError about CUDAExecutionProvider\n",
    "    print('GPU initialization failed (will fall back to CPU):', e)\n",
    "    print('Initializing Pix2Text on CPU...')\n",
    "    p2t = Pix2Text.from_config(device='cpu')\n",
    "    print('Pix2Text initialized on CPU')\n",
    "\n",
    "# Example inference (update path to an actual image in your workspace)\n",
    "img_path = '../datas/FullExpressions/CROHME2019_train_png/001-equation000.png'\n",
    "try:\n",
    "    res = p2t.recognize_formula(img_path, return_text=True)\n",
    "    print(res)\n",
    "except Exception as e:\n",
    "    print('Error running recognition:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a5921d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.234 🚀 Python-3.11.5 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 3769MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../YOLO_dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=math_symbols_detector3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/raclax/Documents/M2/Part2/DL2/Project/DL_project_marie_clara/runs/detect/math_symbols_detector3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../YOLO_dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=math_symbols_detector3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/raclax/Documents/M2/Part2/DL2/Project/DL_project_marie_clara/runs/detect/math_symbols_detector3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117596  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117596  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,137,148 parameters, 11,137,132 gradients, 28.7 GFLOPs\n",
      "\n",
      "Model summary: 129 layers, 11,137,148 parameters, 11,137,132 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 13.3±6.5 MB/s, size: 1.7 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 13.3±6.5 MB/s, size: 1.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/raclax/Documents/M2/Part2/DL2/Project/YOLO_dataset/labels/train.cache... 7993 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7993/7993 6.6Mit/s 0.0s\n",
      "\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 17.4±8.9 MB/s, size: 2.2 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 17.4±8.9 MB/s, size: 2.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/raclax/Documents/M2/Part2/DL2/Project/YOLO_dataset/labels/val.cache... 1999 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1999/1999 1.5Mit/s 0.0s0s\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/raclax/Documents/M2/Part2/DL2/Project/YOLO_dataset/labels/val.cache... 1999 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1999/1999 1.5Mit/s 0.0s0s\n",
      "Plotting labels to /home/raclax/Documents/M2/Part2/DL2/Project/DL_project_marie_clara/runs/detect/math_symbols_detector3/labels.jpg... \n",
      "Plotting labels to /home/raclax/Documents/M2/Part2/DL2/Project/DL_project_marie_clara/runs/detect/math_symbols_detector3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/raclax/Documents/M2/Part2/DL2/Project/DL_project_marie_clara/runs/detect/math_symbols_detector3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/raclax/Documents/M2/Part2/DL2/Project/DL_project_marie_clara/runs/detect/math_symbols_detector3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger un modèle pré-entraîné\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Entraîner\n",
    "results = model.train(\n",
    "    data='../YOLO_dataset/data.yaml',\n",
    "    epochs=10,\n",
    "    imgsz=256,\n",
    "    batch=16,\n",
    "    name='math_symbols_detector'\n",
    ")\n",
    "\n",
    "# Tester\n",
    "results = model.val()\n",
    "\n",
    "# Inférence\n",
    "predictions = model.predict('../YOLO_dataset/images/001-equation001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import RTDETR\n",
    "\n",
    "# Charger le modèle pré-entraîné\n",
    "model = RTDETR('rtdetr-l.pt')  # ou rtdetr-x.pt pour plus de précision\n",
    "\n",
    "# Entraîner\n",
    "results = model.train(\n",
    "    data='./YOLO_dataset/data.yaml',\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    name='math_rtdetr'\n",
    ")\n",
    "\n",
    "# Validation\n",
    "metrics = model.val()\n",
    "\n",
    "# Inférence\n",
    "predictions = model.predict('./YOLO_dataset/images/001-equation001.png', conf=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
